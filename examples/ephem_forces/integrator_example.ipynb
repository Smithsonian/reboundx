{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 999)\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "%matplotlib inline\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from astropy.io import fits\n",
    "\n",
    "import importlib\n",
    "import ctypes\n",
    "\n",
    "import ephem_forces\n",
    "\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "importlib.reload(ephem_forces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we demonstrate the ephemeris-quality integrator by calling a python-wrapped C function that has been compiled into a library that is imported with the ephem_forces.py package.\n",
    "\n",
    "\n",
    "The main function in ephem_forces is \"integration_function\".  It integrates massless test particles in the field of the Sun, planets, moon, and 16 massive asteroids.  It also includes the J2 and J4 gravitational harmonics of the Earth, the J2 gravitational harmonic of the Sun, and the solar GR terms (using the PPN formulation).  \n",
    "\n",
    "The positions of the massive bodies come from two binary files, both from JPL.  The first is for the Sun, planets, and moon.  The other is for the asteroids.  It is important to know that the coordinate frame and units are not flexible.  The coordinate frame is the equatorial ICRF, which is the native coordinate system for the JPL binary files.  Note that this is equatorial rather than ecliptic.  In addition, the native coordinates are barycentric, rather than heliocentric.\n",
    "\n",
    "For units we use solar masses, au, and days.  Furthermore, the independent time coordinate is TDB in Julian days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "integration_function is called with\n",
    "\n",
    "tstart: the start time in JD (TDB)\n",
    "\n",
    "tend: the end time in JD (TDB)\n",
    "\n",
    "tstep: a suggested time step in days.  The integrator might alter this, depending upon the value of epsilon (see below).\n",
    "\n",
    "geocentric: this is an integer (0 or 1).  0 is for barycentric and 1 is for geocentric.\n",
    "n_particles: the integer number of input particles\n",
    "\n",
    "instates: an array of 6-vectors, each of which is the position and velocity of a test particle at tstart.\n",
    "\n",
    "invar_part: an array of integers that specify which real particle is the host for each input variational particle\n",
    "\n",
    "invar: an array of 6-vectors, each of which represents a variational particle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart, tstep, trange = 2458849.5, 20.0, 20\n",
    "geocentric = 0\n",
    "epsilon = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tend = tstart + trange\n",
    "tend = 2468851.011954478\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DE331\n",
    "# (3666) Holman\n",
    "# These are the equatorial, barycentric position and velocity (in AU and AU/day) at\n",
    "# JD 2458849.5 TDB from the JPL Horizons website.\n",
    "#row = [3.338875349745594E+00, -9.176518281675284E-01, -5.038590682977396E-01, 2.805663319000732E-03, 7.550408687780768E-03, 2.980028206579994E-03]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DE441\n",
    "# (3666) Holman\n",
    "#2458849.500000000 = A.D. 2020-Jan-01 00:00:00.0000 TDB [del_T=     69.183900 s]\n",
    "# X = 3.338875349745594E+00 Y =-9.176518281675284E-01 Z =-5.038590682977396E-01\n",
    "# VX= 2.805663319000732E-03 VY= 7.550408687780768E-03 VZ= 2.980028206579994E-03\n",
    "row = [3.338875349745594E+00, -9.176518281675284E-01, -5.038590682977396E-01, 2.805663319000732E-03, 7.550408687780768E-03, 2.980028206579994E-03]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we construct the input.  This will include a real particle with six associated variational particles, one for each phase space dimension.  It will include another six real particles, each offset by a small amount, given by 'scale', along each of those same dimension.  These will be used for testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "instates = np.array([row])\n",
    "n_var = 6\n",
    "n_particles = 7\n",
    "\n",
    "\n",
    "invar_part = np.zeros(6, dtype=int)\n",
    "invar = np.identity(6)\n",
    "\n",
    "scale = 1e-8\n",
    "instatesp = np.array([row]*6)+scale*invar\n",
    "instates=np.vstack([instates, instatesp])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are simpler initial conditions, without the additional real particles."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "instates = np.array([row])\n",
    "n_var = 6\n",
    "n_particles = 1\n",
    "\n",
    "\n",
    "invar_part = np.zeros(6, dtype=int)\n",
    "invar = np.identity(6)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we integrate this one particle for 10,000 days.  The output is:\n",
    "\n",
    "times: a numpy array of the times of output\n",
    "\n",
    "states: a numpy array of 6-vectors, one for each real particle at each output time.\n",
    "\n",
    "var: a numpy array of 6-vectors, one for each variational particle at each output time.\n",
    "\n",
    "var_ng: a numpy array of vectors (length?) to represent the variations with respect to the non-gravitational parameters.\n",
    "\n",
    "status: a flag indicating the outcome of the integration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "times, states, var, var_ng, status = ephem_forces.integration_function(tstart, tend, tstep, geocentric, \n",
    "                                                               n_particles, instates, n_var, invar_part, invar)#, epsilon=1e-8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2468851.011954478,\n",
       " array([ 3.17645719e+00, -1.29320506e+00, -6.51569331e-01,  3.85018878e-03,\n",
       "         7.18909588e-03,  2.79236764e-03]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times[-1], states[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2468851.011954478,\n",
       " array([ 3.17644069e+00, -1.29323746e+00, -6.51581930e-01,  3.85028784e-03,\n",
       "         7.18905495e-03,  2.79234744e-03]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times[-1], states[-1][0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Asteroid (3666) Holman from Horizons sb441-n16\n",
    "\n",
    "2468851.011954478 = A.D. 2047-May-20 12:17:12.8669 TDB [del_T=     69.185185 s]\n",
    " X = 3.176457194815969E+00 Y =-1.293205057535584E+00 Z =-6.515693314430392E-01\n",
    " VX= 3.850188776785952E-03 VY= 7.189095881591583E-03 VZ= 2.792367641688407E-03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3865, 0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(times), status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "GMs = 132712440041.279419"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "au_km = 149597870.700\n",
    "day_sec = 24*60*60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00029591220828411956"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GMsun = GMs*day_sec*day_sec/(au_km*au_km*au_km)\n",
    "GMsun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "GMm = 22031.868551\n",
    "GMmerc = GMm*day_sec*day_sec/(au_km*au_km*au_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GMv = 324858.592000\n",
    "GMven = GMv*day_sec*day_sec/(au_km*au_km*au_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GMe = 398600.435507\n",
    "GMearth = GMe*day_sec*day_sec/(au_km*au_km*au_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GMmn = 4902.800118\n",
    "GMmoon = GMmn*day_sec*day_sec/(au_km*au_km*au_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GMmr = 42828.375816\n",
    "GMmars = GMmr*day_sec*day_sec/(au_km*au_km*au_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GMjup = 126712764.100000\n",
    "GMjupiter = GMjup*day_sec*day_sec/(au_km*au_km*au_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GMsat = 37940584.841800\n",
    "GMsaturn = GMsat*day_sec*day_sec/(au_km*au_km*au_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GMura = 5794556.400000\n",
    "GMuranus = GMura*day_sec*day_sec/(au_km*au_km*au_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GMnep = 6836527.100580\n",
    "GMneptune = GMnep*day_sec*day_sec/(au_km*au_km*au_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GMpl = 975.500000\n",
    "GMpluto = GMpl*day_sec*day_sec/(au_km*au_km*au_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.9125001948001294e-11\n"
     ]
    }
   ],
   "source": [
    "print('%.16le' % (GMmerc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each combination of initial conditional and associated parameters represent a trajectory over some time span, finite or infinite.  For the purposes of fitting an orbit to observations, it is necessary to determine the position, and possibly velocity, at the light-time corrected times of the observations.  Thus, it is often necessary to be able to determine the dynamical state at arbitrary times along the trajectory.  Rather than iteratively integrating to a set of times, it can be more efficient to integrate to a series of times and then interpolate the results for other times.\n",
    "\n",
    "Note that for each overall step taken by the integrator output a number of substeps are included in the output.  I have explored a couple of options for this.  One is output at each of the Gauss-Radau integration substeps.  Another is output at the conventional Chebyshev nodes, as well as the end points.  Both sets of output make interpolation relatively easy, but the latter appears to have better performance.  The goal is to ensure that the error associated with the interpolation is smaller than the error of the integration itself, which is machine precision for IAS15.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesp, statesp, varp, varp_ng, statusp = ephem_forces.production_integration_function_wrapper(tstart, tend, epoch, n_particles, instates, epsilon=-1, tstep=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.polynomial.chebyshev as ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = np.polynomial.chebyshev.chebpts1(7)\n",
    "pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = ch.chebvander(pts, 6 )\n",
    "\n",
    "Vinv = np.linalg.inv(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = statesp[1:8,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = np.dot(Vinv, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-1, 1, 0.001)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0 = ch.chebval(x, f0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y0[0]-y[0])\n",
    "#plt.ylim(-1e-15, 1e-15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesp[0:9], timesp[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesp[8:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(timesp)-1)/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "np.reshape(statesp[i:i+9,:,0:3], (9, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fits = []\n",
    "time_tags = []\n",
    "for i in range(0, len(timesp)-1, 8):\n",
    "    data = np.reshape(statesp[i:i+9,:,0:3], (9, 3))\n",
    "    f = ch.chebfit(timesp[i:i+9]-timesp[i+4], data, 7)\n",
    "    fits.append(f)\n",
    "    time_tags.append(timesp[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits[0][:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_tags = np.array(time_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_segment(time_tags, t, tmax):\n",
    "    if t < time_tags[0] or t > tmax:\n",
    "        return -1\n",
    "    else:\n",
    "        idx = np.searchsorted(time_tags, t)\n",
    "        return idx-1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_tags[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = find_segment(time_tags, 2458889.6, time_tags[-1]+40)\n",
    "fits[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = ch.chebval(x, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0.5*ch.chebpts1(7) + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in x:\n",
    "    print(\"%.16lf\" %(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = [ch.chebval(t-timesp[4], f) for t in timesp[0:9]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(timesp[0:9]-timesp[4], (statesp[0:9,:,2]-model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tend = tstart + trange\n",
    "epoch = tstart + 0.5*trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times2, states2, var2, varp_ng2, statusp2 = ephem_forces.production_integration_function_wrapper(tstart, tend, epoch, n_particles, instates, epsilon=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(times2), len(states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times2, states2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_ng==None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End Other Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "integration_function returns four items.   We  named them times, states, n_out,and n_particles.  \n",
    "\n",
    "\"times\" is an array of the JD TDB times of each output.  \n",
    "\n",
    "\"states\" is an array of each output state at each time.  It is organized first by time and then by state, with each state having six dimensions.  \n",
    "\n",
    "\"n_out\" is the number of outputs.  This is somewhat redundant in python, because you can easily get the number of outputs from the length of \"times\" or the shape of \"states\".  \n",
    "\n",
    "\"n_particles\" is the number of actual particles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The underlying numerical integrator is IAS15 (Rein & Liu 2015), a 15th order predictor-corrector integrator with an adaptive step-size.  Each time step involves eight sub-steps.  We have modified the integrator to output the state at each of the sub-steps in order to support interpolation of the output.\n",
    "\n",
    "Below is a plot of the overall step-size as a function of elapsed integration time.  (The sub-steps are smaller).  A rough periodicity on the ~2000 day asteroid orbital period is evident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=(times-times[0])[::8]\n",
    "dt=t[1:]-t[:-1]\n",
    "\n",
    "plt.plot(t[:-1], dt)\n",
    "plt.xlabel(\"time (days)\")\n",
    "plt.ylabel(\"step-size (days)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invar_part=np.array(6*[0]+6*[1])\n",
    "invar = np.concatenate([np.identity(6), np.identity(6)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is a histogram of the step-sizes.  Most sub-steps are 35-40 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_=plt.hist(dt,bins=30)\n",
    "plt.xlabel(\"step-size (days)\")\n",
    "plt.ylabel(\"N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the xyz values as a function of time.  Keep in mind that the coordinate system is equatorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    plt.plot(times-times[0], states[:,0,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(states[:,0,0], states[:,0,1], linewidth=0.2)\n",
    "plt.axis('square')\n",
    "plt.xlabel('x (AU)')\n",
    "plt.ylabel('y (AU)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can compare the output to what JPL Horizons gives.  We will first grab the time of the last output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states[-1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we grab the output from Horizons for the barycentric equatorial vectors."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# No non-gravs\n",
    "# dt_min = 1e-4\n",
    "# epsilon = 1e-8\n",
    "\n",
    "2468849.500000000 = A.D. 2047-May-19 00:00:00.0000 TDB [del_T=     69.185214 s]\n",
    " X = 3.170610684726161E+00 Y =-1.304064355874703E+00 Z =-6.557860840042533E-01\n",
    " VX= 3.883515127959035E-03 VY= 7.175467895958359E-03 VZ= 2.785507467676363E-03\n",
    " \n",
    " \n",
    "2468849.143245890 = A.D. 2047-May-18 15:26:16.4449 TDB \n",
    " X = 3.169224574251357E+00 Y =-1.306623475655302E+00 Z =-6.567793333511059E-01\n",
    " VX= 3.891371544674626E-03 VY= 7.172234496772530E-03 VZ= 2.783882263299039E-03\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "# No non-gravs\n",
    "# dt_min = 1e-2\n",
    "# epsilon = 1e-8\n",
    "\n",
    "# This is from JPL Horizons, when it used DE441 and sb431-n16\n",
    "#2468851.011954478 = A.D. 2047-May-20 12:17:12.8669 TDB [del_T=     69.185185 s]\n",
    "# X = 3.176457194815969E+00 Y =-1.293205057535584E+00 Z =-6.515693314430392E-01\n",
    "# VX= 3.850188776785952E-03 VY= 7.189095881591583E-03 VZ= 2.792367641688407E-03\n",
    "\n",
    "#DE431\n",
    "holman = np.array([3.176457944594448E+00, -1.293204878669709E+00, -6.515691309014848E-01,\n",
    "     3.850188579021247E-03, 7.189095526429492E-03, 2.792367993782722E-03])\n",
    "\n",
    "#DE441\n",
    "holman = np.array([3.176457194815969E+00, -1.293205057535584E+00, -6.515693314430392E-01, 3.850188776785952E-03, 7.189095881591583E-03, 2.792367641688407E-03])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agreement after ~27 years is excellent, ~25 m or 1e-2 mas (assuming the object is 3 AU away).  This is probably due to the integrator or differences in the precision of the constants.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-9.82105319e-06,  1.15228907e-05,  4.95372366e-06,  3.94689217e-08,\n",
       "         8.67290368e-09,  1.50993994e-09]),\n",
       " array([-2.14261942e-02,  2.51390242e-02,  1.08073384e-02,  8.61077485e-05,\n",
       "         1.89213228e-05,  3.29417483e-06]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((states[-1][0]-holman)/3)*206265, (states[-1][0]-holman)*1.5e8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the output states in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times.shape, states.shape, n_particles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there are extra particles.  In fact, for each actual particle there are six \"variational particles\" or tangent vectors.  These are vectors with the same dimensionality as an actual particle state, but they are the result of integrating the linearized tangent equations, or variational equations.  There is one variational particle for each of the six dimensions, with the initial state being a unit vector.\n",
    "\n",
    "One way to think of the variational equations is to consider two states that are initially close to each other.  As we integrate both the two states will begin to separate.  We can imagine a vector pointing from one of the particles to the other.  (This is a vector is all six dimensions, both positions and velocities.) \n",
    "\n",
    "Suppose that instead of integrating the two particles we could integrate one of the particles and the vector from that particle to the other.  In addition to the equations of motion for the actual particle, we would need the equations of motion for the state vector between the two.  \n",
    "\n",
    "That is what the linearized variational equations are, the equations of motion for the separation between two particles.  As \"linearized\" suggests, these equations are good to first order in the separation.  Also, the variational equations are associated with a big 6x6 matrix, with the terms of the matrix depending only upon the state of the actual particle.  The terms in the matrix are independent of the state vector describing the separation of the particles.  \n",
    "\n",
    "The variational equations are the result of multiplying this big matrix by the state vector of the current separation.  That means we can multiply the same big matrix by any number of state vectors.   The big matrix is sparse (most of the elements are zero). So, the multiplication is not too expensive.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's demonstrate by integrating two actual particles and some tangent vectors.  We will offset the second particle by a small amount along the x-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.shape, var.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The separation of the two actual particles and the tangent vector (appropriately scaled in length) coincide on the scale of the width of the lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(times-times[0], (states[:,2,:]-states[:,0,:])[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the difference between the two approaches more clearly by subtracting one from the other.  They are, indeed, very close.  The difference is due to the nonlinear terms that are not included in the variational equations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(times-times[0], (states[:,1,:]-states[:,0,:]-var[:,0,:]*scale)[:,0])\n",
    "plt.plot(times-times[0], (states[:,2,:]-states[:,0,:]-var[:,1,:]*scale)[:,0])\n",
    "plt.plot(times-times[0], (states[:,3,:]-states[:,0,:]-var[:,2,:]*scale)[:,0])\n",
    "plt.xlabel(\"time (days)\")\n",
    "plt.ylabel(\"AU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try some more challenging cases.  First Apophis, an NEO that makes repeated close approaches to Earth.  It will make an approach on 2021 Mar 06 1:06 UT.  This approach will not be particularly close.  However, the 2029 Apr 13 approach will be extremely close.\n",
    "\n",
    "The initial conditions below are for 2020 Aug 01, before the first approach.  We will integrate through the first approach and to just before the closer second approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ephem_forces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = [-5.145897476309183E-03, -7.554295792725090E-01, -2.803430954241811E-01, 1.994372392258838E-02, 2.695069501106252E-03, 1.506836811826654E-03]\n",
    "    \n",
    "tstart, tstep, trange = 2459062.5, 1.0, 3150\n",
    "geocentric = 0\n",
    "n_particles = 1\n",
    "scale = 1e-8\n",
    "\n",
    "del times\n",
    "del states\n",
    "instates = np.array(row)\n",
    "times, states, n_out, n_particles = ephem_forces.integration_function(tstart, tstep, trange, geocentric, n_particles, instates)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times[-1], states[-1][0]\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Apophis before 2029 encounter\n",
    "\n",
    " 2462214.806617496 = A.D. 2029-Mar-19 07:21:31.7517 TDB \n",
    " X =-1.060823123742407E+00 Y =-1.954485978603505E-02 Z =-3.400944497155493E-02\n",
    " VX= 2.217117676737715E-03 VY=-1.426507080914577E-02 VZ=-5.243738481667273E-03\n",
    " \n",
    " 2462214.377880719 = A.D. 2029-Mar-18 21:04:08.8941 TDB \n",
    " X =-1.061749621090919E+00 Y =-1.342851936299780E-02 Z =-3.176051171408323E-02\n",
    " VX= 2.104893542927364E-03 VY=-1.426673477234808E-02 VZ=-5.247194855985309E-03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apophis_before = np.array([\n",
    "    -1.062610231926071E+00, -7.438995533507307E-03, -2.955702762445418E-02,\n",
    "     1.995149470275391E-03, -1.426773516011195E-02, -5.250341507808811E-03])\n",
    "\n",
    "\n",
    "\n",
    "# Including non-graves\n",
    "# dt_min = 1e-3\n",
    "# epsilon = 1e-8\n",
    "apophis_before = np.array([\n",
    "    -1.061749621090919E+00, -1.342851936299780E-02, -3.176051171408323E-02,\n",
    "     2.104893542927364E-03, -1.426673477234808E-02, -5.247194855985309E-03])\n",
    "\n",
    "# No non-gravs\n",
    "apophis_before = np.array([\n",
    "         -1.060823123742407E+00, -1.954485978603505E-02, -3.400944497155493E-02, \n",
    "          2.217117676737715E-03, -1.426507080914577E-02, -5.243738481667273E-03])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states[-1][0], (states[-1][0]-apophis_before)*1.5e8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The largest discrepancy is ~119 km just before the 2029 close approach.\n",
    "\n",
    "Now I will include the non-gravitational terms, using the A2 value provided by JPL Horizons (A1 and A3 = 0.0).\n",
    "\n",
    "At the moment, the non-grav values are hard-coded.  The code needs to be recompiled and the library reloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ephem_forces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = [-5.145897476309183E-03, -7.554295792725090E-01, -2.803430954241811E-01, 1.994372392258838E-02, 2.695069501106252E-03, 1.506836811826654E-03]\n",
    "    \n",
    "tstart, tstep, trange = 2459062.5, 1.0, 3150\n",
    "geocentric = 0\n",
    "n_particles = 1\n",
    "scale = 1e-8\n",
    "\n",
    "del times\n",
    "del states\n",
    "instates = np.array(row)\n",
    "times, states, n_out, n_particles = ephem_forces.integration_function(tstart, tstep, trange, geocentric, n_particles, instates)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states[-1][0], (states[-1][0]-apophis_before)*1.5e8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1e-3*24*3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = [-5.145897476309183E-03, -7.554295792725090E-01, -2.803430954241811E-01, 1.994372392258838E-02, 2.695069501106252E-03, 1.506836811826654E-03]\n",
    "    \n",
    "tstart, tstep, trange = 2459062.5, 1.0, 3150\n",
    "geocentric = 0\n",
    "n_particles = 1\n",
    "scale = 1e-8\n",
    "\n",
    "del times\n",
    "del states\n",
    "instates = np.array(row)\n",
    "times, states, n_out, n_particles = ephem_forces.integration_function(tstart, tstep, trange, geocentric, n_particles, instates)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = [-5.145897476309183E-03, -7.554295792725090E-01, -2.803430954241811E-01, 1.994372392258838E-02, 2.695069501106252E-03, 1.506836811826654E-03]\n",
    "\n",
    "rows = [[-5.145897476309183E-03, -7.554295792725090E-01, -2.803430954241811E-01, 1.994372392258838E-02, 2.695069501106252E-03, 1.506836811826654E-03],\n",
    "       [-5.145898476309183E-03, -7.554295792725090E-01, -2.803430954241811E-01, 1.994372392258838E-02, 2.695069501106252E-03, 1.506836811826654E-03]]\n",
    "   \n",
    "   \n",
    "tstart, tstep, trange = 2459062.5, 1.0, 3200\n",
    "geocentric = 0\n",
    "n_particles = 2\n",
    "scale = 1e-8\n",
    "\n",
    "instates = np.array(rows)\n",
    "times, states, n_out, n_particles = ephem_forces.integration_function(tstart, tstep, trange, geocentric, n_particles, instates)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(states[-1][0]-states[-1][1])*1.5e8, (states[0][0]-states[0][1])*1.5e8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apophis_before = np.array([\n",
    "    -1.062610231926071E+00, -7.438995533507307E-03, -2.955702762445418E-02,\n",
    "     1.995149470275391E-03, -1.426773516011195E-02, -5.250341507808811E-03])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart, tstep, trange = 2462213.958072528, 1.0, 2462263.697021989-2462216.753921871\n",
    "geocentric = 0\n",
    "n_particles = 1\n",
    "scale = 1e-8\n",
    "\n",
    "instates = apophis_before\n",
    "times, states, n_out, n_particles = ephem_forces.integration_function(tstart, tstep, trange, geocentric, n_particles, instates)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states[-1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Apophis after 2029 encounter\n",
    "\n",
    "2462262.879945683 = A.D. 2029-May-06 09:07:07.3070 TDB \n",
    " X =-6.283889415589419E-01 Y =-6.496621274217913E-01 Z =-2.652090553526072E-01\n",
    " VX= 1.554844044456806E-02 VY=-1.021342630556588E-02 VZ=-3.747872168881012E-03\n",
    " \n",
    " 2462267.413982561 = A.D. 2029-May-10 21:56:08.0933 TDB \n",
    " X =-5.556667507595004E-01 Y =-6.935286876694169E-01 Z =-2.812079254765416E-01\n",
    " VX= 1.651530555748704E-02 VY=-9.118721403508922E-03 VZ=-3.302633165414243E-03\n",
    " \n",
    " 2462262.140873468 = A.D. 2029-May-05 15:22:51.4676 TDB \n",
    " X =-6.398193089596965E-01 Y =-6.420513159000456E-01 Z =-2.624136502848963E-01\n",
    " VX= 1.538287990494170E-02 VY=-1.038167285986079E-02 VZ=-3.816576674477177E-03\n",
    "2462262.503900107 = A.D. 2029-May-06 00:05:36.9692 TDB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apophis_after = np.array([\n",
    "                 -6.283889415589419E-01, -6.496621274217913E-01, -2.652090553526072E-01,\n",
    "                 1.554844044456806E-02, -1.021342630556588E-02, -3.747872168881012E-03])\n",
    "\n",
    "apophis_after = np.array([\n",
    "    -5.556667507595004E-01, -6.935286876694169E-01, -2.812079254765416E-01, \n",
    "    1.651530555748704E-02, -9.118721403508922E-03, -3.302633165414243E-03])\n",
    "\n",
    "apophis_after = np.array([\n",
    "    -6.398193089596965E-01, -6.420513159000456E-01, -2.624136502848963E-01,\n",
    "    1.538287990494170E-02, -1.038167285986079E-02, -3.816576674477177E-03])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states[-1][0], (states[-1][0]-apophis_after)*1.5e8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the largest discrepancy is ~14 km.  How carefully the very close approaches are handled matters, as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 999)\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from astropy.io import fits\n",
    "\n",
    "import importlib\n",
    "import ctypes\n",
    "\n",
    "import ephem_forces\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try geocentric integrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = [6.634500992578179E-02, 2.122458699845356E-03, -3.507415858744104E-04,\n",
    "     -1.060257698567525E-03, 6.078332955992950E-04, 2.240712392485767E-04]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart, tstep, trange = 2459062.5, -1.0, -400\n",
    "geocentric = 1\n",
    "n_particles = 1\n",
    "scale = 1e-8\n",
    "\n",
    "instates = np.array(row)\n",
    "timesb, statesb, n_out, n_particles = ephem_forces.integration_function(tstart, tstep, trange, geocentric, n_particles, instates)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statesb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(statesb[:,0,0], statesb[:,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del statesb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart, tstep, trange = 2459062.5, 1.0, 400\n",
    "geocentric = 1\n",
    "n_particles = 1\n",
    "scale = 1e-8\n",
    "instates = np.array(row)\n",
    "\n",
    "timesf, statesf, n_out, n_particles = ephem_forces.integration_function(tstart, tstep, trange, geocentric, n_particles, instates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statesf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(statesf[:,0,0], statesf[:,0,1])\n",
    "plt.plot(statesb[:,0,0], statesb[:,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart, tstep, trange = timesb[-1], 1.0, 400\n",
    "instatesb = statesb[-1][0].copy()\n",
    "timesf, statesf, n_out, n_particles = ephem_forces.integration_function(tstart, tstep, trange, geocentric, n_particles, instatesb)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(statesb[:,0,0], statesb[:,0,1])\n",
    "\n",
    "plt.plot(statesf[:,0,0], statesf[:,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statesb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "2462263.697021989 = A.D. 2029-May-07 04:43:42.6999 TDB \n",
    " X = 7.771821449378258E-02 Y = 1.444568330466675E-02 Z = 2.318152988506329E-02\n",
    " VX= 3.531021355764523E-03 VY= 8.992784904633009E-04 VZ= 1.064745760510192E-03\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apophis_geo_after=np.array([\n",
    "    7.771821449378258E-02, 1.444568330466675E-02, 2.318152988506329E-02, \n",
    "    3.531021355764523E-03, 8.992784904633009E-04, 1.064745760510192E-03])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(states[-1][0]-apophis_geo_after)*1.5e8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is worse.  I wonder if this is due to the interpolated acceleration of the Earth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=(times-times[0])[::8]\n",
    "dt=t[1:]-t[:-1]\n",
    "\n",
    "plt.plot(t[:-1], dt)\n",
    "plt.xlabel(\"time (days)\")\n",
    "plt.ylabel(\"step-size (days)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(30000/1.5e8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import demo_2particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_2particles.states[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_2particles.times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(demo_2particles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1.9705228610653722e+00-1.970522858564949E+00)*1.5e8\n",
    "(6.4568366227497698e-01-6.456836770230201E-01)*1.5e8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_2particles.times.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_2particles.states[:,0,:], demo_2particles.times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx= (demo.states[:,1,:]-demo.states[:,0,:])\n",
    "tdx = demo.states[:,7,:]*1e-6\n",
    "\n",
    "dy= (demo.states[:,2,:]-demo.states[:,0,:])\n",
    "tdy = demo.states[:,8,:]*1e-6\n",
    "\n",
    "dz= (demo.states[:,3,:]-demo.states[:,0,:])\n",
    "tdz = demo.states[:,9,:]*1e-6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdx = demo.states[:,7,:]*1e-6\n",
    "tdy = demo.states[:,8,:]*1e-6\n",
    "tdz = demo.states[:,9,:]*1e-6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tangents = demo.states[:,1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tangents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(demo.times, (tdx - dx))\n",
    "plt.plot(demo.times-demo.times[0], (tdx - dx))\n",
    "plt.plot(demo.times-demo.times[0], (tdy - dy))\n",
    "plt.plot(demo.times-demo.times[0], (tdz - dz))\n",
    "#plt.xlim(0,200)\n",
    "#plt.ylim(0, 10e-14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(demo.times-demo.times[0], (demo.states[:,6,:]-demo.states[:,0,:])[:,0]-demo.states[:,12,:][:,0]*1e-6)\n",
    "#plt.plot(demo.times-demo.times[0], demo.states[:,7,:][:,0]*1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(demo.states[:,0,:][:,0], demo.states[:,0,:][:,1])\n",
    "plt.xlim(0, 4)\n",
    "plt.ylim(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(demo.instates)\n",
    "del(demo.times)\n",
    "del(demo.states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports / set-up\n",
    "import numpy as np ;\n",
    "import os,sys ;\n",
    "sys.path.append(os.environ['REBX_DIR']) ;\n",
    "from examples.ephem_forces.ephem_forces import integration_function ;\n",
    "tstart=2456117.641933589 ;\n",
    "tstep=20 ;\n",
    "trange=1000 ;\n",
    "geocentric=False ;\n",
    "n_particles=1 ;\n",
    "reparsed_input=np.array([-2.0938349524664743,1.0009137200092553,0.41979849545335507,-0.004226738336365523, -0.009129140909705197, -0.0036271214539287102])\n",
    "\n",
    "\n",
    "# Call that will randomly crash with malloc ...\n",
    "integration_function(tstart, tstep, trange, geocentric,n_particles, reparsed_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = np.array((3.338876057509365E+00, -9.176517956664152E-01, -5.038590450387491E-01, 2.805663678557796E-03, 7.550408259144305E-03, 2.980028369986096E-03))\n",
    "scales = np.logspace(-7, -3, 81)\n",
    "results_dict = {}\n",
    "\n",
    "for scale in scales:\n",
    "    print('%12.3e' % scale)\n",
    "\n",
    "    with open('test_ic', 'w') as f:\n",
    "        f.write('tepoch 2458849.5\\n')\n",
    "        f.write('tstart 2458849.5\\n')\n",
    "        f.write('tstep 20.0\\n')\n",
    "        f.write('trange 500.\\n')\n",
    "        f.write('geocentric 0\\n')\n",
    "\n",
    "        f.write('state\\n%23.16le %23.16le %23.16le\\n%23.16le %23.16le %23.16le\\n' % tuple(state))\n",
    "        for v in state+np.identity(6)*scale:\n",
    "            f.write('state\\n%23.16le %23.16le %23.16le\\n%23.16le %23.16le %23.16le\\n' % tuple(v))\n",
    "\n",
    "    output = subprocess.run([\"./rebound\", \"test_ic\", str(scale)], stdout=subprocess.PIPE)\n",
    "\n",
    "    arr =np.loadtxt('out_states.txt')\n",
    "\n",
    "    t = arr[:,0]\n",
    "\n",
    "    px = arr[:,1:4]\n",
    "    py = arr[:,7:10]\n",
    "    pz = arr[:,13:16]\n",
    "    \n",
    "    results_dict[scale] = t, px, py, pz\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(results):\n",
    "    t, p0, p1, p2 = results\n",
    "    d = np.linalg.norm(p0, axis=1)\n",
    "    z = np.polyfit(t, d, deg=2)\n",
    "    f = np.poly1d(z)\n",
    "    plt.plot(t, d-f(t), label='x')\n",
    "    #plt.plot(t, d, label='x')\n",
    "    d = np.linalg.norm(p1, axis=1)\n",
    "    z = np.polyfit(t, d, deg=2)\n",
    "    f = np.poly1d(z)\n",
    "    plt.plot(t, d-f(t), label='y')\n",
    "    #plt.plot(t, d, label='y')\n",
    "    d = np.linalg.norm(p2, axis=1)\n",
    "    z = np.polyfit(t, d, deg=2)\n",
    "    f = np.poly1d(z)\n",
    "    plt.plot(t, d-f(t), label='z')\n",
    "    #plt.plot(t, d, label='z')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_x = np.array(sorted([(k, np.linalg.norm(p0[-1]), np.linalg.norm(p1[-1]), np.linalg.norm(p2[-1])) for k, (t, p0, p1, p2) in results_dict.items()]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(prec_x[:,0], prec_x[:, 1])\n",
    "plt.plot(prec_x[:,0], prec_x[:, 2])\n",
    "plt.plot(prec_x[:,0], prec_x[:, 3])\n",
    "plt.yscale('log')\n",
    "plt.xscale ('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(results_dict[1e-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.logspace(-8, -2, num=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.solve(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, -1, -1], [2, 3, 2], [4, 3, -2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([1, 8, -2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.solve(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[4, 6, -3], [3, 4, -6], [6, -3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([24, 2, 46])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.solve(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctypes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "libc = CDLL(\"libc.dylib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(libc.time(None))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = c_int(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(i.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i.value=-99\n",
    "print(i.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"Hello, World\"\n",
    "c_s = c_wchar_p(s)\n",
    "print(c_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_wchar_p(139966785747344)\n",
    "print(c_s.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_s.value = \"Hi, there\"\n",
    "print(c_s)              # the memory location has changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_wchar_p(139966783348904)\n",
    ">>> print(c_s.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s)                # first object is unchanged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = create_string_buffer(3)            # create a 3 byte buffer, initialized to NUL bytes\n",
    "print(sizeof(p), repr(p.raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = create_string_buffer(b\"Hello\")     # create a buffer containing a NUL terminated string\n",
    "print(sizeof(p), repr(p.raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(repr(p.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = create_string_buffer(b\"Hello\", 10) # create a 10 byte buffer\n",
    "print(sizeof(p), repr(p.raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.value = b\"Hi\"\n",
    "print(sizeof(p), repr(p.raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printf = libc.printf\n",
    "printf(b\"Hello, %s\\n\", b\"World!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printf(b\"Hello, %S\\n\", \"World!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hello, World!\n",
    "14\n",
    ">>> printf(b\"Hello, %S\\n\", \"World!\")\n",
    "Hello, World!\n",
    "14\n",
    ">>> printf(b\"%d bottles of beer\\n\", 42)\n",
    "42 bottles of beer\n",
    "19\n",
    ">>> printf(b\"%f bottles of beer\\n\", 42.5)\n",
    "Traceback (most recent call last):\n",
    "  File \"<stdin>\", line 1, in <module>\n",
    "ArgumentError: argument 2: exceptions.TypeError: Don't know how to convert parameter 2\n",
    ">>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.power(213/4, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.17*12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.2*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5*39192/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "712/5274"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "51414/7703674"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5070/51414"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "25*5/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4*6*9/3.62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3*6*9/2.42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2*7*9/4.84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# make up some data\n",
    "x = [datetime.datetime.now() + datetime.timedelta(hours=i) for i in range(12)]\n",
    "y = [i+random.gauss(0,1) for i,_ in enumerate(x)]\n",
    "\n",
    "# plot\n",
    "plt.bar(x,y)\n",
    "# beautify the x-labels\n",
    "plt.gcf().autofmt_xdate()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/mholman/Dropbox/misc/dates.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"/Users/mholman/Dropbox/misc/funding.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['d'] = df.date.apply(lambda x: pd.to_datetime(x))\n",
    "df2['d'] = df2.date.apply(lambda x: pd.to_datetime(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative = np.cumsum(df.delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labor=np.cumsum((cumulative+6)*(df.d-df.d.shift())/(365.25*np.timedelta64(1,'D')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.dates as mdates\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.scatter(df.d, cumulative+6)\n",
    "\n",
    "#ax2 = ax.twinx()\n",
    "\n",
    "linestyle = (0, (1, 4))\n",
    "\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "#ax2.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "panel = datetime.datetime(2015, 5, 5)\n",
    "ax.axvline(panel, -10, 20, ls=linestyle, color='r')\n",
    "\n",
    "prop = datetime.datetime(2016, 10, 28)\n",
    "ax.axvline(prop, -10, 20, ls=linestyle, color='g')\n",
    "\n",
    "funds = datetime.datetime(2017, 1, 27)\n",
    "ax.axvline(funds, -10, 20, color='g')\n",
    "\n",
    "ma = datetime.datetime(2017, 5, 29)\n",
    "ax.axvline(ma, -10, 20, ls='--', color='black')\n",
    "\n",
    "sk = datetime.datetime(2018, 8, 13)\n",
    "ax.axvline(sk, -10, 20, ls='--', color='black')\n",
    "\n",
    "mug1 = datetime.datetime(2017, 6, 22)\n",
    "ax.axvline(mug1, -10, 20, ls='dotted', color='r')\n",
    "\n",
    "mug2 = datetime.datetime(2017, 12, 18)\n",
    "ax.axvline(mug2, -10, 20, ls='dotted', color='r')\n",
    "\n",
    "mug3 = datetime.datetime(2018, 6, 28)\n",
    "ax.axvline(mug3, -10, 20, ls='dotted', color='r')\n",
    "\n",
    "neocp = datetime.datetime(2018, 11, 1)\n",
    "ax.axvline(neocp, -10, 20, ls='solid', color='blue')\n",
    "\n",
    "mug4 = datetime.datetime(2018, 12, 17)\n",
    "ax.axvline(mug4, -10, 20, ls='dotted', color='r')\n",
    "\n",
    "mug5 = datetime.datetime(2019, 7, 9)\n",
    "ax.axvline(mug5, -10, 20, ls='dotted', color='r')\n",
    "\n",
    "mug6 = datetime.datetime(2019, 12, 10)\n",
    "ax.axvline(mug6, -10, 20, ls='dotted', color='r')\n",
    "\n",
    "mug7 = datetime.datetime(2020, 6, 11)\n",
    "ax.axvline(mug7, -10, 20, ls='dotted', color='r')\n",
    "\n",
    "mug8 = datetime.datetime(2020, 12, 2)\n",
    "ax.axvline(mug8, -10, 20, ls='dotted', color='r')\n",
    "\n",
    "covid = datetime.datetime(2020, 3, 13)\n",
    "ax.axvline(covid, -10, 20, ls='dashdot', color='purple')\n",
    "\n",
    "vms = datetime.datetime(2019, 6, 6)\n",
    "ax.axvline(vms, -10, 20, ls='dashdot', color='purple')\n",
    "\n",
    "d_start = datetime.datetime(2018, 10, 1)\n",
    "d_end = datetime.datetime(2019, 2, 10)\n",
    "#ax.axhline(y=3, xmin=0.62, xmax=0.68, color='black')\n",
    "\n",
    "\n",
    "dates = datetime.datetime(2016, 11, 1), datetime.datetime(2017, 11, 1), datetime.datetime(2018, 11, 1), datetime.datetime(2019, 11, 1), datetime.datetime(2020, 11, 1)\n",
    "levels = 7, 7, 10, 11, 11\n",
    "#ax.plot(dates, levels, color='gray')\n",
    "\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('MPC FTEs')\n",
    "\n",
    "\n",
    "#ax2.set_ylabel('Total Funding ($M)')\n",
    "\n",
    "funding = df2['total_funding']\n",
    "d = df2['d']\n",
    "\n",
    "linestyle = (0, (1, 4))\n",
    "\n",
    "#ax2.xaxis_date() \n",
    "#ax2.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "#ax2.plot(d, funding/1e6)\n",
    "\n",
    "#ax2.plot(df.d, labor)\n",
    "\n",
    "plt.savefig('/Users/mholman/Dropbox/misc/FTEs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.dates as mdates\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "#ax.scatter(df.d, cumulative+6)\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "linestyle = (0, (1, 4))\n",
    "\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "ax2.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "panel = datetime.datetime(2015, 5, 5)\n",
    "ax.axvline(panel, -10, 20, ls=linestyle, color='r')\n",
    "\n",
    "prop = datetime.datetime(2016, 10, 28)\n",
    "ax.axvline(prop, -10, 20, ls=linestyle, color='g')\n",
    "\n",
    "funds = datetime.datetime(2017, 1, 27)\n",
    "ax.axvline(funds, -10, 20, color='g')\n",
    "\n",
    "ma = datetime.datetime(2017, 5, 29)\n",
    "#ax.axvline(ma, -10, 20, ls='--', color='black')\n",
    "\n",
    "sk = datetime.datetime(2018, 8, 13)\n",
    "#ax.axvline(sk, -10, 20, ls='--', color='black')\n",
    "\n",
    "mug1 = datetime.datetime(2017, 6, 22)\n",
    "ax.axvline(mug1, -10, 20, ls='dotted', color='r')\n",
    "\n",
    "mug2 = datetime.datetime(2017, 12, 18)\n",
    "ax.axvline(mug2, -10, 20, ls='dotted', color='r')\n",
    "\n",
    "mug3 = datetime.datetime(2018, 6, 28)\n",
    "ax.axvline(mug3, -10, 20, ls='dotted', color='r')\n",
    "\n",
    "neocp = datetime.datetime(2018, 11, 1)\n",
    "#ax.axvline(neocp, -10, 20, ls='solid', color='blue')\n",
    "\n",
    "mug4 = datetime.datetime(2018, 12, 17)\n",
    "ax.axvline(mug4, -10, 20, ls='dotted', color='r')\n",
    "\n",
    "mug5 = datetime.datetime(2019, 7, 9)\n",
    "ax.axvline(mug5, -10, 20, ls='dotted', color='r')\n",
    "\n",
    "mug6 = datetime.datetime(2019, 12, 10)\n",
    "ax.axvline(mug6, -10, 20, ls='dotted', color='r')\n",
    "\n",
    "mug7 = datetime.datetime(2020, 6, 11)\n",
    "ax.axvline(mug7, -10, 20, ls='dotted', color='r')\n",
    "\n",
    "mug8 = datetime.datetime(2020, 12, 2)\n",
    "ax.axvline(mug8, -10, 20, ls='dotted', color='r')\n",
    "\n",
    "covid = datetime.datetime(2020, 3, 13)\n",
    "#ax.axvline(covid, -10, 20, ls='dashdot', color='purple')\n",
    "\n",
    "vms = datetime.datetime(2019, 6, 6)\n",
    "#ax.axvline(vms, -10, 20, ls='dashdot', color='purple')\n",
    "\n",
    "d_start = datetime.datetime(2018, 10, 1)\n",
    "d_end = datetime.datetime(2019, 2, 10)\n",
    "#ax.axhline(y=3, xmin=0.62, xmax=0.68, color='black')\n",
    "\n",
    "\n",
    "dates = datetime.datetime(2016, 11, 1), datetime.datetime(2017, 11, 1), datetime.datetime(2018, 11, 1), datetime.datetime(2019, 11, 1), datetime.datetime(2020, 11, 1)\n",
    "levels = 7, 7, 10, 11, 11\n",
    "#ax.plot(dates, levels, color='gray')\n",
    "\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('MPC FTE-years')\n",
    "\n",
    "\n",
    "ax2.set_ylabel('Funding ($M)')\n",
    "\n",
    "funding = df2['total_funding']\n",
    "coh_me = df2['coh_me']\n",
    "expected = df2['expected']\n",
    "d = df2['d']\n",
    "\n",
    "linestyle = (0, (1, 4))\n",
    "\n",
    "ax2.xaxis_date() \n",
    "ax2.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "ax2.plot(d, funding/1e6)\n",
    "ax2.plot(d, coh_me/1e6, 'red')\n",
    "ax2.plot(d, expected/1e6)\n",
    "\n",
    "ax.plot(df.d, labor-9.7, 'black')\n",
    "ax.set_ylim(-0.1, 40)\n",
    "ax2.set_ylim(-0.1, 8)\n",
    "\n",
    "\n",
    "plt.savefig('/Users/mholman/Dropbox/misc/funding.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(df.d, cumulative+6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative+6, df.d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative+6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spicey as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(440e6-45.9e6)/(2*1.5e6*30)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
